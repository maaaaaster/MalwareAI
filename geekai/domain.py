import os
import re
import pandas as pd
from publicsuffix import PublicSuffixList
from sklearn import preprocessing
import codecs
psl_file = codecs.open('suffix.dat', encoding='utf8')
psl = PublicSuffixList(psl_file)
p = re.compile('^((25[0-5]|2[0-4]\d|[01]?\d\d?)\.){3}(25[0-5]|2[0-4]\d|[01]?\d\d?)$')  

phase1 = 'D:/ai/geek/phase1/trace2_test'

def checkip(ip):  
    if p.match(ip):  
        return True  
    else:  
        return False

def noHeadDomain(domain):
    vals = domain.split('.')
    if vals[0] in ['www','wap']:
        return '.'.join(vals[1:])
    return domain

def processDomain(data):
    return data.map(noHeadDomain)

def readPSLDomain(data):
    data['pslDomain'] = data.map(lambda x:psl.get_public_suffix(x))



def whiteDomainSet():
    whiteSet = set()
    for line in open('prank.top.1m.20180322').readlines():
        domain = line.split('\t')[0]
        whiteSet.add(psl.get_public_suffix(domain))
    for line in open('top-1m.csv').readlines():
        domain = line.split(',')[1].strip()
        whiteSet.add(psl.get_public_suffix(domain))
    print('all white %d'%len(whiteSet))
    return whiteSet

def loadDomainsFromDir(basedir):
    webfile = os.path.join(basedir,'trojan_web.csv')
    ipfile = os.path.join(basedir,'fqdn_ip.csv')
    reginfofile = os.path.join(basedir,'fqdn_reginfo.csv')
    domain_ip = pd.read_csv(ipfile)['site']
    domain_reg = pd.read_csv(reginfofile)['domain']
    domain_web = pd.read_csv(webfile)['url'].map(lambda x:x.split('://')[-1].split('/')[0].split(':')[0])
    domain_ip = processDomain(domain_ip)
    domain_reg = processDomain(domain_reg)
    domain_web = processDomain(domain_web)
    allDomains = set(domain_ip) | set(domain_reg) | set(domain_web)
    nxDomains = set(domain_web) - (set(domain_ip) | set(domain_reg))
    whiteSet = whiteDomainSet()
    result = []
    pslMap = {}
    for domain in nxDomains:
        if checkip(domain):
            continue
        pslDomain = psl.get_public_suffix(domain)
        if pslDomain in whiteSet:
            continue
        result.append({
            'domain':domain,
            'host':pslDomain,
            'top':pslDomain[pslDomain.find('.'):]
        })
        if pslDomain not in pslMap:
            pslMap[pslDomain] = 0
        pslMap[pslDomain]+=1
    for data in result:
        data['subCount'] = pslMap[data['host']]
    df = pd.DataFrame(result)
    df.to_csv('cluster_domain.csv',index=False)    




if __name__=='__main__':
    loadDomainsFromDir(phase1)