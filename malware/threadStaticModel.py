from sklearn import feature_extraction
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.metrics import accuracy_score
import lightgbm as lgb
from sklearn.metrics import log_loss
import pandas as pd
import os
import json
from loopcheck import checkAPIs

tfidfFeatureName = 'data/thread_tfidf.csv'
basicName = 'data/thread_basic.csv'
traininputfile = 'data/train_thread_list.csv'
testinputfile = 'data/test_thread_list.csv'


def apis2str(apis):
    apis = eval(apis)
    return ' '.join(apis)


def file2xy(filename):
    df = pd.read_csv(filename)#.iloc[0:100,:]
    corpus = df['apilist'].map(apis2str)
    if 'label' in df.columns:
        extra =df[['file_id','tid','label']]
    else:
        extra = df[['file_id', 'tid']]
        extra.loc[:,('label')]= -1

    return extra,corpus

def makeTFFeatures():
    extra1,corpus1 =file2xy(traininputfile)
    extra2,corpus2 = file2xy(testinputfile)
    extra = pd.concat([extra1,extra2])
    corpus = pd.concat([corpus1,corpus2])
    
    vectorizer = TfidfVectorizer(lowercase=False,ngram_range=(1,1))
    transformer=TfidfTransformer()
    tfidf=transformer.fit_transform(vectorizer.fit_transform(corpus))
    word=vectorizer.get_feature_names()
    weight=tfidf.toarray()
    data = pd.DataFrame(weight)
    data.to_csv(tfidfFeatureName,header=word,index=0)
    extra.to_csv(basicName,index=0)
    return data


def loadTF_IDF():
    basic = pd.read_csv(basicName)
    tfidf = pd.read_csv(tfidfFeatureName)
    trainLen = 887947
    basic = basic.iloc[0:trainLen,:]
    tfidf = tfidf.iloc[0:trainLen,:]
    x = tfidf
    y = basic['label']
    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.1)
    train_data=lgb.Dataset(x_train,label=y_train)
    #
    param = {'num_leaves':100, 'objective':'multiclass','max_depth':8,'learning_rate':.05,'max_bin':200,'num_class':6}
    param['metric'] = ['multi_logloss']
    # #
    # # num_round=20
    #
    # param = {'objective': 'multiclass', 'learning_rate': .05, 'num_class': 6, 'max_bin': 300}
    # param.update({'max_depth': 10, 'num_leaves': 550})
    # param['metric'] = ['multi_logloss']
    #
    num_round = 10000
    # # test_data = lgb.Dataset(x_test,y_test)
    test_data = lgb.Dataset(x_test, y_test, reference=train_data)
    #
    # lgbm=lgb.train(param,train_data,num_round)
    lgbm = lgb.train(param, train_data, num_round, valid_sets=[test_data], early_stopping_rounds=10)
    lgbm.save_model('thread_model.txt', num_iteration=lgbm.best_iteration)
    checkModel(y_test, lgbm.predict(x_test))


def checkModel(y_test, y_pred):
    newLabel = []
    result = {}
    classLen = len(y_pred[0])
    for i in range(len(y_pred)):
        label = 0
        for j in range(classLen):
            if y_pred[i][j] > 0.5:
                label = j
        if label not in result:
            result[label] = 0
        result[label]+=1
        newLabel.append(label)

    accuracy_lgbm = accuracy_score(newLabel, y_test)
    print(accuracy_lgbm)

if __name__ == "__main__":
    # makeTFFeatures()
    loadTF_IDF()