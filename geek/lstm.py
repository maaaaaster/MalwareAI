
import pandas as pd
import numpy as np
from sklearn import preprocessing
from keras.utils.np_utils import to_categorical
from keras.layers import Masking, Embedding
from keras.layers import LSTM

le = preprocessing.LabelEncoder()

sequenceLength = -1
def loadTrain():
    global sequenceLength
    label = pd.read_csv('D:\\ai\\geek\\phase1\\trace1_train1\\safetype.txt',sep=';')
    y = label['family_id']
    le.fit(y)
    encoded_y = le.transform(y)
    Y = to_categorical(encoded_y)
    train = pd.read_csv('D:\\ai\\geek\\phase1\\trace1_train1\\sandbox_behaviorlist.txt',sep=';')        
    result = []
    for behaviour in train['behavior_list']:
        if type(behaviour) == float:
            []
        else:
            bList = behaviour.split(',')
            sequenceLength = max(sequenceLength,len(bList))
            tempList = [int(x) for x in bList]
        # tempList.reshape(1,tempList.size,1)
        result.append(tempList)
        # np.array([int(x) for x in bList])
        # result = result.reshape(1,result.size,1)        
        # result = to_categorical( ,num_classes=201)
    for belist in result:
        nowlen = len(belist)
        if nowlen < sequenceLength:
            belist += [-1]*(sequenceLength-nowlen)
    X = np.array(result).reshape(len(result),sequenceLength,1)
    return X,Y

X,Y = loadTrain()
#encoding=utf-8
from keras.datasets import mnist
from keras.layers import Dense, LSTM
from keras.utils import to_categorical
from keras.models import Sequential  

nb_lstm_outputs = 30  #神经元个数
nb_time_steps = sequenceLength  #时间序列长度
nb_input_vector = 1 #输入序列

(x_train, y_train), (x_test, y_test) = mnist.load_data()
print(x_train.shape)

x_train, y_train = X, Y
print(x_train.shape)


# x_train = x_train.astype('float32')
# x_test = x_test.astype('float32')
# x_train /= 255
# x_test /= 255
# y_train = to_categorical(y_train, num_classes=10)
# y_test = to_categorical(y_test, num_classes=10)

model = Sequential()
model.add(Masking(mask_value= -1,input_shape=(sequenceLength, 1,)))

model.add(LSTM(units=nb_lstm_outputs, input_shape=(nb_time_steps, nb_input_vector)))
model.add(Dense(6, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit(x_train, y_train, epochs=20, batch_size=128, verbose=1)

# model.summary()
 
# score = model.evaluate(x_test, y_test,batch_size=128, verbose=1)
# print(score)