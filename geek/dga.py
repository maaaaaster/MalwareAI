import csv
import os
from tools import *
import pandas as pd
from sklearn.preprocessing import OneHotEncoder


def extractDomain(filename):
    domains = set()
    ips = set()
    inf = open(filename,encoding='utf-8')
    reader = csv.reader(inf)
    headings = next(reader)
    for data in reader:
        url = data[1]
        if '/' in url:
            vals = url.split('/')
            fulldomain = vals[2].split(':')[0]
        else:
            fulldomain = url
        if checkip(fulldomain):
            ips.add(fulldomain)
        else:
            domains.add(fulldomain)
    return domains,ips


def loadDomains():
    domains,IPs = extractDomain(fileMap['web'])
    registeredDomain= set()
    for key in ['fqdn','region']:
        newDomain,newIP = extractDomain(fileMap[key])
        domains = domains | newDomain
        registeredDomain = registeredDomain | newDomain    
    return domains,registeredDomain

def recordList(data,outname):
    outf = open(outMap[outname],'w+')
    for line in data:
        outf.write(line+'\n')

def makeDomainList():
    domains,registeredDomain = loadDomains()
    print(len(domains),len(registeredDomain),len(domains-registeredDomain))
    recordList(registeredDomain,'registered_domain')
    recordList(domains,'all_domain')

def ip2domain():
    ipMap = {}
    filename = fileMap['fqdn']
    inf = open(filename,encoding='utf-8')
    reader = csv.reader(inf)
    headings = next(reader)
    for data in reader:
        domain = data[1]
        ip = data[2]
        if ip not in ipMap:
            ipMap[ip] =  set()
        ipMap[ip].add(domain)
    for ip in ipMap:
        if len(ipMap[ip])>1:
            print(ipMap[ip])
            
def noRegisterDomain():
    noRegisterDomain = set()
    domains,registeredDomain = loadDomains()
    for domain in domains:
        if domain not in registeredDomain and len(domain.split('.'))==2:
            noRegisterDomain.add(domain)
        
    inf = open(fileMap['region'],encoding='utf-8')
    reader = csv.reader(inf)
    headings = next(reader)
    for data in reader:
        if len(data[2])<1 and not checkip(data[1]):
            domain = data[1].lower()
            noRegisterDomain.add(domain)
    print(len(noRegisterDomain))
    return noRegisterDomain


def staticFeature(domain):
    vals = domain.split('.')
    charNum =0
    numberNum = 0
    allLen = 0
    specialChar = 0
    for char in domain:
        if char == '.':
            continue        
        allLen+=1
        if char>='0' and  char<='9':
            numberNum+=1
        elif char>='a' and char<='z':
            charNum+=1
        else:
            specialChar+=1
    return {   
    'domain':domain,
    'enddomain':vals[-1],
    'block':len(vals),
    'charLen':charNum,
    'numLen':numberNum,
    'specialChar':specialChar    
    } 

def clusterFromDomains(domains):
    check = []
    for domain in domains:
        features = staticFeature(domain)
        check.append(features)
    oneHotFeature(check,'enddomain')
    train = pd.DataFrame(check)    
    train.to_csv(outMap['domainFeature'],index =0)


def DBSCANCluster():
    domain2group = {}
    X = pd.read_csv(outMap['domainFeature'])
    domains = X['domain']
    del(X['domain'])
    # from sklearn.cluster import KMeans
    # y_pred = KMeans(n_clusters=100, random_state=9).fit_predict(X)
    from sklearn.cluster import DBSCAN
    y_pred = DBSCAN().fit_predict(X)
    group2domain = {}
    outf = open(outMap['dga2level'],'w+')
    outf.write('domain,family\n')
    for i in range(len(y_pred)):
        domain2group[domains[i]] = y_pred[i]
        if y_pred[i] not in group2domain:
            group2domain[y_pred[i]] = []
        group2domain[y_pred[i]].append(domains[i])
    for group in group2domain:
        if group <0:
            continue
        for domain in group2domain[group]:
            outf.write('%s,%d\n'%(domain,group))

    return domain2group



def readDomainSet():
    alldomains,registereddomains = loadDomains()
    sha2domain = {}
    domain2sha = {}    
    for key in ['web','fqdn','region']:
        filename = fileMap[key]
        inf = open(filename,encoding='utf-8')
        reader = csv.reader(inf)
        headings = next(reader)
        for data in reader:
            sha = data[0]
            if sha not in sha2domain:
                sha2domain[sha] = set()
            url = data[1]
            if '/' in url:
                vals = url.split('/')
                fulldomain = vals[2].split(':')[0]
            else:
                fulldomain = url
            if not checkip(fulldomain):            
                if fulldomain not in domain2sha:
                    domain2sha[fulldomain] = set()
                sha2domain[sha].add(fulldomain)
                domain2sha[fulldomain].add(sha)
    return sha2domain,domain2sha

def expendDomain():
    secondRegistered = set()
    sha2domain,domain2sha = readDomainSet()
    domain2group = {}
    index = 10000
    for domain in domain2sha:
        domain2group[domain] = index
        index+=1
    domain2group.update(DBSCANCluster())
    clusterSet(domain2group,sha2domain)




def dga2graph():
    sha2domain,domain2sha = readDomainSet()
    outf = open('graph.txt','a+')
    inf = open(outMap['dga2level'],encoding='utf-8')
    reader = csv.reader(inf)    
    headings = next(reader)
    for data in reader:
        domain = data[0]
        group = data[1]
        for sha in domain2sha[domain]:
            outf.write('%s,domain2level_%s\n'%(sha,group))


if __name__=='__main__':
    # makeDomainList()
    # ip2domain()
    # clusterFromDomains(noRegisterDomain())
    # clusterFromDomains(extractDomain(fileMap['web'])[0])
    # DBSCANCluster()
    # expendDomain()
    # checkFamily()
    dga2graph()
    
