from sklearn import feature_extraction
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.metrics import accuracy_score
import lightgbm as lgb
from sklearn.metrics import log_loss
import pandas as pd
import os
import json

tfidfFeatureName = 'thread_tfidf.csv'
inputfile = 'thread_list.csv'
def loadTFFeatures():
    if os.path.exists(tfidfFeatureName):
        data = pd.read_csv(tfidfFeatureName)
    else:
        df = pd.read_csv(inputfile)
        corpus,extra = fileData(df)   #  threadData(df)#[seq.replace(';',' ') for seq in df['seq']]
        vectorizer=CountVectorizer()
        vectorizer = TfidfVectorizer(lowercase=False,ngram_range=(1,3),max_features=1000)
        transformer=TfidfTransformer()
        tfidf=transformer.fit_transform(vectorizer.fit_transform(corpus))
        word=vectorizer.get_feature_names()#获取词袋模型中的所有词语
        weight=tfidf.toarray()#将tf-idf矩阵抽取出来，元素a[i][j]表示j词在i类文本中的tf-idf权重
        data = pd.DataFrame(weight)
        data.to_csv(tfidfFeatureName,header=word,index=0)
    return data


def labels():
    df = pd.read_csv(inputfile)
    return df['label']

def key2str(apistr):
    str = apistr[1:-1].strip("'").replace(',',' ')
    return str
def fileData(df):
    y = df[['file_id','tid','label']]
    x = df['apilist'].map(key2str)
    return x,y

def loadTF_IDF():
    x = loadTFFeatures()
    y = labels()
    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.3)
    train_data=lgb.Dataset(x_train,label=y_train)

    # param = {'num_leaves':60, 'objective':'multiclass','max_depth':7,'learning_rate':.05,'max_bin':200,'num_class':6}
    # param['metric'] = ['auc']
    #
    # num_round=20

    param = {'objective': 'multiclass', 'learning_rate': .05, 'num_class': 6, 'max_bin': 300}
    param.update({'max_depth': 10, 'num_leaves': 550})
    param['metric'] = ['multi_logloss']

    num_round = 1000
    # test_data = lgb.Dataset(x_test,y_test)
    test_data = lgb.Dataset(x_test, y_test, reference=train_data)

    # lgbm=lgb.train(param,train_data,num_round)
    lgbm = lgb.train(param, train_data, num_round, valid_sets=[test_data], early_stopping_rounds=10)
    checkModel(y_test, lgbm.predict(x_test))
    lgbm.save_model('thread_model.txt', num_iteration=lgbm.best_iteration)

def checkModel(y_test, y_pred):
    newLabel = []
    result = {}
    classLen = len(y_pred[0])
    for i in range(len(y_pred)):
        label = 0
        for j in range(classLen):
            if y_pred[i][j] > 0.5:
                label = j
        if label not in result:
            result[label] = 0
        result[label]+=1
        newLabel.append(label)

    accuracy_lgbm = accuracy_score(newLabel, y_test)
    print(accuracy_lgbm)

if __name__ == "__main__":
    loadTF_IDF()