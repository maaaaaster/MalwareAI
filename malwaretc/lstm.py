import keras
import numpy as np
from keras.layers import Dense, LSTM
from keras.utils import to_categorical
from keras.models import Sequential  
from keras.models import load_model
from keras.callbacks import ModelCheckpoint
from keras.utils.np_utils import to_categorical
from keras.layers import Masking, Embedding
from sklearn import preprocessing

import os
import pandas as pd

from config import *

le = preprocessing.LabelEncoder()


sequenceLength = 5000
nb_lstm_outputs = 30  #神经元个数
nb_time_steps = sequenceLength  #时间序列长度
nb_input_vector = 1 #输入序列

modelname = 'my_model.h5'
outClasses = 6

def loadData():
    df = pd.read_csv(outseqFile)
    y = df['label']
    le.fit(y)
    encoded_y = le.transform(y)
    Y = to_categorical(encoded_y)
    # print(y.drop_duplicates())
    result = []
    for behaviour in df['seq']:
        bList = behaviour.split(';')
        tempList = []
        for x in bList:
            now = int(x)
            if len(tempList)>1 and tempList[-1]==now and tempList[-2]==now:
                continue
            else:
                tempList.append(now)


        result.append(tempList)
    X = keras.preprocessing.sequence.pad_sequences(result, maxlen=sequenceLength, dtype='int32',value=-1)
    X = X.reshape(len(result),sequenceLength,1)
    return X,Y

def checkData():
    x,y = loadData()

    if os.path.exists(modelname):
        model = load_model(modelname)
    else:
        model = Sequential()
        model.add(Masking(mask_value= -1,input_shape=(sequenceLength, 1,)))

        model.add(LSTM(units=nb_lstm_outputs, input_shape=(nb_time_steps, nb_input_vector)))
        model.add(Dense(outClasses, activation='softmax'))

        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    modelcheck = ModelCheckpoint(filepath=modelname)
    
    model.fit(x, y, epochs=30, batch_size=128, verbose=1,callbacks=[modelcheck])


checkData()